{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing SS 20 - Assignment - 09\n",
    "\n",
    "### Deadline is 24.6.2020 at 11:55am\n",
    "\n",
    "Please solve the assignments together with a partner.\n",
    "I will run every notebook. Make sure the code runs through. Select `Kernel` -> `Restart & Run All` to test it.\n",
    "Please strip the output from the cells, either select `Cell` -> `All Output` -> `Clear` or use the `nb_strip_output.py` script / git hook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the plots inside the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "from skimage.data import chelsea\n",
    "import zipfile\n",
    "pylab.rcParams['figure.figsize'] = (12, 12)   # This makes the plot bigger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JPEG\n",
    "\n",
    "The Wikipedia page about [JPEG-Komprimierung](https://de.wikipedia.org/wiki/JPEG#Die_JPEG-Komprimierung) gives\n",
    "a good overview. Wikipedia assume that the image data is uint8. That is why we do not convert it to float in this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start with the input image\n",
    "img = chelsea()\n",
    "\n",
    "block_size = 8\n",
    "# add some padding so the image can be evenly sliced into blocks\n",
    "pad_x = 0 if img.shape[0] % (block_size * 2) == 0 else (img.shape[0] // (block_size * 2) + 1) * (block_size * 2) - img.shape[0]\n",
    "pad_y = 0 if img.shape[1] % (block_size * 2) == 0 else (img.shape[1] // (block_size * 2) + 1) * (block_size * 2) - img.shape[1]\n",
    "img = np.pad(img, ((0, pad_x), (0, pad_y), (0, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Blocks:\n",
    "    \"\"\"Transforms an image to blocks. A (512, 512) image will become an (64, 64, 8, 8) numpy array\"\"\"\n",
    "    def __init__(self, block_size=8):\n",
    "        self.block_size = block_size\n",
    "        \n",
    "    def __call__(self, img):\n",
    "        b = self.block_size\n",
    "        height, width = img.shape\n",
    "\n",
    "        assert img.shape[0] % b == 0\n",
    "        assert img.shape[1] % b == 0\n",
    "        blocks = np.zeros((height // b, width // b, b, b), dtype=img.dtype)\n",
    "        for i in range(0, height // b):\n",
    "            for j in range(0, width // b):\n",
    "                blocks[i, j] = img[i*b:(i+1)*b, j*b:(j+1)*b]\n",
    "        return blocks\n",
    "\n",
    "    def invert(self, blocks):\n",
    "        bh, bw = blocks.shape[:2]\n",
    "        b = self.block_size\n",
    "        heigth, width = (bh*self.block_size, bw*self.block_size)\n",
    "\n",
    "        img = np.zeros((heigth, width), dtype=blocks.dtype)\n",
    "        for i in range(0, bh):\n",
    "            for j in range(0, bw):\n",
    "                img[i*b:(i+1)*b, j*b:(j+1)*b] = blocks[i, j]\n",
    "        return img\n",
    "\n",
    "# test block operation on R-Channel\n",
    "img_blocks = Blocks(block_size=8)(img[:, :, 0])\n",
    "print(img_blocks.shape)\n",
    "assert img_blocks.shape[2:] == (8, 8)\n",
    "img_inv = Blocks(block_size=8).invert(img_blocks)\n",
    "\n",
    "# the two images should be the same again after inverting\n",
    "assert (img[:, :, 0] == img_inv).all()\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(img[:, :, 0], cmap='gray')\n",
    "plt.subplot(122)\n",
    "plt.imshow(img_inv, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Exercise 1 - Chroma Subsampling - 2 Points\n",
    "Apply chroma subsampling to the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChromaSubsampling:\n",
    "    \"\"\"See https://en.wikipedia.org/wiki/YCbCr.\"\"\"\n",
    "    ycbcr = np.array([\n",
    "        [0.299,  0.587,  0.114],\n",
    "        [-0.168736, -0.331264,  0.5],\n",
    "        [0.5, -0.418688, -0.0813],\n",
    "    ])\n",
    "    def __call__(self, rgb_img):\n",
    "        \"\"\"Transforms the rgb image to YCbCr. The cb and cr channels have half the resolution of the Y-channel.\n",
    "           You can simply use the mean of four neighbours.\n",
    "        \"\"\"\n",
    "        shape = rgb_img.shape\n",
    "        \n",
    "        ycbcr_img = np.dot(self.ycbcr, rgb_img.reshape(-1, 3).T)\n",
    "        ycbcr_img = ycbcr_img.T.reshape(shape)\n",
    "        ycbcr_img[:,:, [1,2]] += 128\n",
    "        # subsample the cb and cr channel, so that they have half the resolution of the Y-channel.\n",
    "        # A simple thing might be to use the mean of 4 neighbours.\n",
    "        # your code here\n",
    "        return ycbcr_img[:, :, 0], ycbcr_img[:, :, 1], ycbcr_img[:, :, 2]\n",
    "    \n",
    "    def invert(self, inputs):\n",
    "        y, cb, cr = inputs\n",
    "        # your code here\n",
    "        return np.stack([y, cb, cr], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Test the subsampling: The cr and cb channel should be half the resolution of the y channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y, cb, cr = ChromaSubsampling()(img)\n",
    "plt.subplot(141)\n",
    "plt.title('Luminance Y')\n",
    "plt.imshow(y, cmap='gray')\n",
    "plt.subplot(142)\n",
    "plt.title('Subsampled Chrominance Cr')\n",
    "plt.imshow(cb, cmap='gray')\n",
    "plt.subplot(143)\n",
    "plt.title('Subsampled Chrominance Cb')\n",
    "plt.imshow(cr, cmap='gray')\n",
    "plt.subplot(144)\n",
    "plt.title('Inverted')\n",
    "plt.imshow(ChromaSubsampling().invert((y,cb,cr)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Exercise 2 - DCT on 8x8 blocks - 2 Points\n",
    "Apply DCT on 8x8 blocks. You may use np.fft` or `scipy.fftpack`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class DCTofBlocks:\n",
    "    def __call__(self, blocks):\n",
    "        \"\"\"Returns the DCT of the blocks. The position (i, j) is a 2-dim numpy array with the dct coefficents.\"\"\"\n",
    "        # you can use any function from np.fft or scipy.fftpack\n",
    "        # your code here\n",
    "        return blocks\n",
    "    \n",
    "    def invert(self, blocks):\n",
    "        \"\"\"Computes the inverse DCT.\"\"\"\n",
    "        # you can use any function from np.fft or scipy.fftpack\n",
    "        # your code here\n",
    "        return blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# print some blocks and their DCT on the y channel\n",
    "y_block = Blocks()(y)\n",
    "y_block_dct = DCTofBlocks()(y_block)\n",
    "plt.subplot(441)\n",
    "plt.imshow(y_block[0, 0, :, :], cmap='gray')\n",
    "plt.subplot(442)\n",
    "plt.imshow(y_block[0, 1, :, :], cmap='gray')\n",
    "plt.subplot(443)\n",
    "plt.imshow(y_block[0, 2, :, :], cmap='gray')\n",
    "plt.subplot(444)\n",
    "plt.imshow(y_block[0, 3, :, :], cmap='gray')\n",
    "\n",
    "plt.subplot(445)\n",
    "plt.imshow(y_block_dct[0, 0, :, :], cmap='jet', vmax = np.max(y_block_dct[0, 0, :, :]) * 0.01,vmin = 0)\n",
    "plt.subplot(446)\n",
    "plt.imshow(y_block_dct[0, 1, :, :], cmap='jet', vmax = np.max(y_block_dct[0, 0, :, :]) * 0.01,vmin = 0)\n",
    "plt.subplot(447)\n",
    "plt.imshow(y_block_dct[0, 2, :, :], cmap='jet', vmax = np.max(y_block_dct[0, 0, :, :]) * 0.01,vmin = 0)\n",
    "plt.subplot(448)\n",
    "plt.imshow(y_block_dct[0, 3, :, :], cmap='jet', vmax = np.max(y_block_dct[0, 0, :, :]) * 0.01,vmin = 0)\n",
    "plt.show()\n",
    "\n",
    "# show full image\n",
    "dct_img = Blocks().invert(y_block_dct)\n",
    "plt.imshow(dct_img, cmap='gray', vmax = np.max(dct_img) * 0.01,vmin = 0)\n",
    "plt.show()\n",
    "\n",
    "# apply inverse DCT\n",
    "plt.imshow(Blocks().invert(DCTofBlocks().invert(y_block_dct)), cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Exercise 3 - Quantization - 2 Points\n",
    "Apply quantization on the image with a threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Quantization:\n",
    "    def __init__(self, threshold=1):\n",
    "        # you can use the Q matrix from Wikipedia or invent your own.\n",
    "        self.q_matrix = []\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def __call__(self, blocks):\n",
    "        \"\"\"Divides the blocks by the `q_matrix` elementwise. Coefficents under the `threshold` will be set to zero.\"\"\"\n",
    "        # your code here\n",
    "        return blocks\n",
    "    \n",
    "    def invert(self, blocks):\n",
    "        \"\"\" For inverting multiply your elements piecewise with the Q-Matrix\"\"\"\n",
    "        return blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try out Quantization. You should see that with increasing threshold the image becomes more blurry compared to the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "quant_1 = Quantization(threshold=2)(y_block_dct)\n",
    "quant_img_1 = Blocks().invert(Quantization().invert(quant_1))\n",
    "quant_2 = Quantization(threshold=20)(y_block_dct)\n",
    "quant_img_2 = Blocks().invert(Quantization().invert(quant_2))\n",
    "plt.subplot(331)\n",
    "plt.imshow(quant_img_1, cmap='gray', vmax = np.max(quant_img_1) * 0.01,vmin = 0)\n",
    "plt.subplot(332)\n",
    "plt.imshow(Blocks().invert(DCTofBlocks().invert(Quantization().invert(quant_1))), cmap='gray')\n",
    "plt.subplot(333)\n",
    "plt.imshow(y, cmap='gray')\n",
    "plt.subplot(334)\n",
    "plt.imshow(quant_img_2, cmap='gray', vmax = np.max(quant_img_2) * 0.01,vmin = 0)\n",
    "plt.subplot(335)\n",
    "plt.imshow(Blocks().invert(DCTofBlocks().invert(Quantization().invert(quant_2))), cmap='gray')\n",
    "plt.subplot(336)\n",
    "plt.imshow(y, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Exercise 4 - Pick n-th highest - 2 Points\n",
    "Implement the pick n-th highest algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class PickNthHighest:\n",
    "    def __init__(self, n=1):\n",
    "        self.n = n\n",
    "\n",
    "    def __call__(self, blocks):\n",
    "        \"\"\"Pick the nth-highest frequencies\"\"\"\n",
    "        # your code here\n",
    "        return blocks\n",
    "\n",
    "    def invert(self, blocks):\n",
    "        \"\"\"There is no way to invert this operation. Just return the inputs.\"\"\"\n",
    "        return blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try out pick n-th highest compression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pick_1 = PickNthHighest(n=16)(y_block_dct)\n",
    "pick_img_1 = Blocks().invert(pick_1)\n",
    "pick_2 = PickNthHighest(n=8)(y_block_dct)\n",
    "pick_img_2 = Blocks().invert(pick_2)\n",
    "plt.subplot(331)\n",
    "plt.imshow(pick_img_1, cmap='gray', vmax = np.max(pick_img_1) * 0.01,vmin = 0)\n",
    "plt.subplot(332)\n",
    "plt.imshow(Blocks().invert(DCTofBlocks().invert(pick_1)), cmap='gray')\n",
    "plt.subplot(333)\n",
    "plt.imshow(y, cmap='gray')\n",
    "plt.subplot(334)\n",
    "plt.imshow(pick_img_2, cmap='gray', vmax = np.max(pick_img_2) * 0.01,vmin = 0)\n",
    "plt.subplot(335)\n",
    "plt.imshow(Blocks().invert(DCTofBlocks().invert(pick_2)), cmap='gray')\n",
    "plt.subplot(336)\n",
    "plt.imshow(y, cmap='gray')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Entropy encoding\n",
    "This class applies the zigzag algorithm to compress the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class ZigZag:\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "        \"\"\"Adapted from here: https://rosettacode.org/wiki/Zig-zag_matrix#Python\"\"\"\n",
    "        def key(pair):\n",
    "            x, y = pair\n",
    "            return x+y, -y if (x+y) % 2 else y\n",
    "\n",
    "        n = 8\n",
    "        indexorder = sorted(((x,y) for x in range(n) for y in range(n)), key=key)\n",
    "        self.xs = np.zeros((self.n**2,), dtype=np.int)\n",
    "        self.ys = np.zeros((self.n**2,), dtype=np.int)\n",
    "        self.back = np.zeros((n, n), dtype=np.int)\n",
    "        for i, (x, y) in enumerate(indexorder):\n",
    "            self.xs[i] = x\n",
    "            self.ys[i] = y\n",
    "            self.back[x, y] = i\n",
    "            \n",
    "    def __call__(self, blocks):\n",
    "        bh, bw, h, w = blocks.shape\n",
    "        zigzack_blocks = np.zeros((bh, bw, h*w), dtype=blocks.dtype)\n",
    "        for i, block_row in enumerate(blocks):\n",
    "            for j, block in enumerate(block_row):\n",
    "                zigzack_blocks[i, j] = block[self.xs, self.ys] \n",
    "        return zigzack_blocks\n",
    "    \n",
    "    def invert(self, zigzack_blocks):\n",
    "        bh, bw, hw = zigzack_blocks.shape\n",
    "        h = int(np.sqrt(hw))\n",
    "        blocks = np.zeros((bh, bw, h, h), dtype=zigzack_blocks.dtype)\n",
    "        for i, zigzack_row in enumerate(zigzack_blocks):\n",
    "            for j, zigzack in enumerate(zigzack_row):\n",
    "                blocks[i, j] = zigzack[self.back] \n",
    "        return blocks\n",
    "\n",
    "zigzag = ZigZag(8)\n",
    "range_mat = np.arange(64).reshape(1, 1, 8, 8)\n",
    "zigzack_mat = zigzag(range_mat)\n",
    "assert (zigzag.invert(zigzack_mat) == range_mat).all()\n",
    "\n",
    "print(range_mat)\n",
    "print(zigzack_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Compress:\n",
    "    \"\"\"This class compresses arbitray input using the bz2 algorithm\"\"\"\n",
    "    def __init__(self, dtype=np.int8):\n",
    "        self.dtype = dtype\n",
    "        self.max_value = (np.iinfo(dtype).max  / 1.1)\n",
    "        \n",
    "    def __call__(self, arr):\n",
    "        # print(\"dtype: {}\".format(arr.dtype))\n",
    "        # print(\"max: {}, min: {}\".format(arr.max(), arr.min()))\n",
    "        scale = max(abs(arr.max()), abs(arr.min()))\n",
    "        arr = arr / scale \n",
    "        arr = arr * self.max_value\n",
    "        arr = np.rint(arr)\n",
    "        arr = arr.astype(self.dtype)\n",
    "        bytearr = arr.data.tobytes()\n",
    "        \n",
    "        return zipfile.bz2.compress(bytearr), arr.shape, arr.dtype, scale\n",
    "    \n",
    "    def invert(self, inputs):\n",
    "        bytearr, shape, dtype, scale = inputs\n",
    "        decom_bytes = zipfile.bz2.decompress(bytearr)\n",
    "        arr = np.frombuffer(decom_bytes, dtype=self.dtype)\n",
    "        arr = arr.astype(dtype)\n",
    "        arr = arr / self.max_value * scale\n",
    "        return arr.reshape(shape)\n",
    "\n",
    "range_mat = np.arange(64, dtype=np.float64).reshape(1, 1, 8, 8)\n",
    "compress = Compress()\n",
    "compressed = compress(range_mat)\n",
    "# print((compress.invert(compressed)))\n",
    "assert np.allclose(compress.invert(compressed), range_mat, 0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Jpeg:\n",
    "    def __init__(self, stages):\n",
    "        self.stages = stages\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        y, cb, cr = ChromaSubsampling()(img)\n",
    "        outputs = []\n",
    "        for input in [y, cb, cr]:\n",
    "            output = input\n",
    "            for stage in self.stages:\n",
    "                input = output\n",
    "                try:\n",
    "                    output = stage(input)\n",
    "                except:\n",
    "                    print(\"Error in Stage: {}\".format(type(stage).__name__))\n",
    "                    raise\n",
    "            outputs.append(output)\n",
    "        return outputs\n",
    "    \n",
    "    def invert(self, inputs):\n",
    "        outputs = []\n",
    "        for output in inputs:\n",
    "            for stage in self.stages[::-1]:\n",
    "                input = output\n",
    "                try:\n",
    "                    output = stage.invert(input)\n",
    "                except:\n",
    "                    print(\"Error in Stage: {}\".format(type(stage).__name__))\n",
    "                    raise\n",
    "            outputs.append(output)\n",
    "        y, cb, cr = outputs\n",
    "        return ChromaSubsampling().invert([y, cb, cr])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_size_jpeg(jpeg_output):\n",
    "    \"\"\"Summs the number of bytes over the different compression channels: y, cb, cr\"\"\"\n",
    "    nb_bytes = sum([len(x[0]) for x in jpeg_output])\n",
    "    return \"{:.1f}KB\".format(nb_bytes / 1000)\n",
    "\n",
    "def total_size_numpy(arr):\n",
    "    return \"{:.1f}KB\".format(len(arr.data.tobytes()) / 1000)\n",
    "\n",
    "def naive_compression_size(arr):\n",
    "    bytearr = arr.data.tobytes()\n",
    "    nb_bytes = len(zipfile.bz2.compress(bytearr))\n",
    "    return \"{:.1f}KB\".format(nb_bytes / 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the jpeg pipeline\n",
    "# for testing you can use only the first ones.\n",
    "# maybe you have to adjust the Quantization threshold settings.\n",
    "jpeg = Jpeg([Blocks(8), DCTofBlocks(), Quantization(threshold=10), ZigZag(8), Compress(np.int8)])\n",
    "\n",
    "img_jpeg = jpeg(img)\n",
    "img_reconstruct = jpeg.invert(img_jpeg)\n",
    "assert img_reconstruct.shape == img.shape\n",
    "# once you implemented ChromaSubsampling.invert this should have colors :)\n",
    "plt.imshow(img_reconstruct / 255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromasubsampling_compression = Jpeg([Blocks(8), Compress()])\n",
    "print(\"No compression: \" + total_size_numpy(img))\n",
    "print(\"Direct compression of the image: \" + naive_compression_size(img))\n",
    "print(\"Cromasubsampling and compression: \" + total_size_jpeg(chromasubsampling_compression(img)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Exercise 5 - Pipeline comparison - 2 Points\n",
    "Compare different pipeline setups and complete the tasks below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the size of the images if the zigzag encoding is removed.\n",
    "# Does the size change if the quantization threshold increases?\n",
    "jpeg = Jpeg([Blocks(8), DCTofBlocks(), Quantization(threshold=10), Compress(np.uint8)])\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the image quality of the `Quantization` vs. the `PickNthHighest` compressions. Make sure that the outputs\n",
    "# are roughly the same size. Why is one better then the other one?\n",
    "\n",
    "# your code here\n",
    "\n",
    "# your short answer here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
